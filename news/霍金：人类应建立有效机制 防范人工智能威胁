　　中新网3月14日电 据外媒报道，英国剑桥大学物理学家霍金日前在接受媒体采访时，再次强调人类建立有效机制，防止人工智能(AI)对人类的威胁进一步上升。　　据报道，霍金在接受采访时表示，包括AI在内的新科技若持续发展，可能会通过核战争或生物战争摧毁人类；人类则需要利用逻辑和理性去控制未来可能出现的威胁。　　霍金还就应对AI的威胁建议称，人类可以组成某种形式的联合政府来防范AI可能带来的威胁。　　数年前霍金已经表示，发展全面的人工智能可能导致人类的毁灭。　　　　霍金说，人工智能的发展可能帮助人类消除疾病，消除贫困，阻止气候变化，但是也可能产生人们不愿意看到的种种后果，包括产生自主武器，造成经济灾难，以及发展出同人类发生冲突时拥有自己意愿的机器。　　“简言之，强大人工智能的崛起可能是人类遇到的最好的事情，也可能是最坏的事情，但我们还不知道答案。”